<!DOCTYPE html>
<html>
<head>
<title>InfraProposal.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="llm-hackathon-infrastructure-proposal">LLM Hackathon Infrastructure Proposal</h1>
<p><strong>DRAFT DOCUMENT: This proposal is a draft offering and all details are subject to change</strong></p>
<h2 id="overview">Overview</h2>
<p>This document outlines the proposed infrastructure setup for the OMC hackathon focusing on LLM exploration. The architecture allows OMC employees to experiment with three different LLM models while authenticating through the existing OMC ADFS system, with added RAG (Retrieval Augmented Generation) capabilities.</p>
<h2 id="llm-models">LLM Models</h2>
<p>We propose offering the following three models to showcase different capabilities and use cases:</p>
<ol>
<li>
<p><strong>Llama 3 70B</strong> - Meta's flagship large language model, offering strong general-purpose capabilities across a wide range of tasks including reasoning, code generation, and creative writing.</p>
</li>
<li>
<p><strong>CodeLlama 34B</strong> - Specialized for code generation and understanding, optimized for programming tasks and technical assistance. Ideal for developers wanting to explore code completion, bug fixing, and technical documentation.</p>
</li>
<li>
<p><strong>DeepSeek Coder 7B</strong> - A specialized coding model known for its efficiency and strong performance despite its smaller size. Excellent for programming tasks, debugging, and technical documentation, with a different approach than CodeLlama. The model will be deployed in a network-isolated environment to prevent any external communications, ensuring complete privacy for OMC use.</p>
</li>
</ol>
<h2 id="infrastructure-architecture">Infrastructure Architecture</h2>
<h3 id="components">Components</h3>
<ol>
<li>
<p><strong>Authentication Layer</strong></p>
<ul>
<li>Integration with OMC ADFS</li>
<li>Domain-restricted access</li>
<li>Self-service registration for all OMC employees</li>
</ul>
</li>
<li>
<p><strong>User Interface</strong></p>
<ul>
<li>Open WebUI (formerly ollama-webui)</li>
<li>Single interface for accessing all three models</li>
<li>Persistent chat history and user preferences</li>
</ul>
</li>
<li>
<p><strong>Backend Infrastructure</strong></p>
<ul>
<li>Three separate model-specific Auto Scaling Groups</li>
<li>Load balancers for each model cluster</li>
<li>Centralized session and data storage</li>
<li>Vector database for RAG capabilities</li>
</ul>
</li>
<li>
<p><strong>RAG Components</strong></p>
<ul>
<li>Document processing pipeline</li>
<li>Vector embeddings generation</li>
<li>Vector database (PostgreSQL with pgvector)</li>
<li>Retrieval middleware integration with Open WebUI</li>
</ul>
</li>
</ol>
<h3 id="technical-implementation">Technical Implementation</h3>
<h4 id="authentication-flow">Authentication Flow</h4>
<ol>
<li>Register Open WebUI as a new application in OMC ADFS</li>
<li>Configure claim rules to pass OMC email information</li>
<li>Implement authentication proxy to validate ADFS assertions</li>
<li>Users authenticate via familiar company login screens</li>
</ol>
<h4 id="aws-architecture">AWS Architecture</h4>
<pre class="hljs"><code><div>[OMC ADFS Authentication]
            ↓
      [Load Balancer]
            ↓
    [Open WebUI Instances]
            ↓
 ┌─────────────┬─────────────┬─────────────┬─────────────┐
 ↓             ↓             ↓             ↓             ↓
[Llama 3 70B] [CodeLlama 34B] [DeepSeek 7B] [DynamoDB]   [PostgreSQL/pgvector]
[GPU ASG]     [GPU ASG]      [GPU ASG]     [Sessions]   [Vector Store]
                                                              ↑
                                                              ↓
                                                     [Document Processor]
                                                     [Lambda Functions]
</div></code></pre>
<h4 id="aws-resources-required">AWS Resources Required</h4>
<ol>
<li>
<p><strong>EC2 Instances</strong></p>
<ul>
<li>Open WebUI: t3.medium instances (2-3 for redundancy)</li>
<li>Llama 3 70B: g5.2xlarge instances (2-3 nodes)</li>
<li>CodeLlama 34B: g5.xlarge instances (2-3 nodes)</li>
<li>DeepSeek Coder 7B: g4dn.xlarge instances (2-3 nodes)</li>
</ul>
</li>
<li>
<p><strong>Supporting Services</strong></p>
<ul>
<li>Application Load Balancers (4 total)</li>
<li>DynamoDB table for session management</li>
<li>RDS PostgreSQL with pgvector extension for vector storage</li>
<li>S3 bucket for model storage and document repository</li>
<li>Lambda functions for document processing</li>
<li>SQS for document processing queue</li>
</ul>
</li>
<li>
<p><strong>Networking</strong></p>
<ul>
<li>VPC with public and private subnets</li>
<li>Security groups for access control</li>
<li>Connection to OMC network for ADFS</li>
<li>Network isolation for models (especially DeepSeek) to prevent external communication</li>
<li>Egress controls to ensure no model can &quot;phone home&quot; or access the internet</li>
<li>Private endpoints for all AWS services to maintain complete data isolation</li>
</ul>
</li>
</ol>
<h4 id="scaling-considerations">Scaling Considerations</h4>
<p>Each model is isolated in its own Auto Scaling Group to prevent resource contention. For the hackathon, we recommend starting with a fixed number of instances rather than implementing complex auto-scaling:</p>
<ul>
<li>3 instances for Llama 3 70B (most resource-intensive)</li>
<li>3 instances for CodeLlama 34B (specialized model)</li>
<li>2 instances for DeepSeek Coder 7B (efficient coding model)</li>
</ul>
<p>This configuration can support approximately 50-75 concurrent users during the hackathon.</p>
<h2 id="user-experience">User Experience</h2>
<ol>
<li>
<p><strong>Authentication</strong></p>
<ul>
<li>Users navigate to the hackathon URL</li>
<li>They're redirected to the familiar OMC ADFS login if not already authenticated</li>
<li>After authentication, they're taken to the Open WebUI interface</li>
</ul>
</li>
<li>
<p><strong>Model Selection</strong></p>
<ul>
<li>Users select which model they want to interact with via a dropdown</li>
<li>Behind the scenes, requests route to the appropriate model cluster</li>
<li>Users can switch models at any time during their session</li>
</ul>
</li>
<li>
<p><strong>RAG Capabilities</strong></p>
<ul>
<li>Users can upload documents (PDF, DOCX, TXT, etc.) to create knowledge bases</li>
<li>Documents are automatically processed, chunked, and embedded</li>
<li>Users can query models with context from their uploaded documents</li>
<li>System retrieves relevant information to augment model responses</li>
</ul>
</li>
<li>
<p><strong>Persistent Experience</strong></p>
<ul>
<li>Chat history is maintained across sessions</li>
<li>User preferences and custom prompts are saved</li>
<li>Knowledge bases and documents remain available for future sessions</li>
<li>Experience remains consistent even if backend instances change</li>
</ul>
</li>
</ol>
<h2 id="cost-considerations">Cost Considerations</h2>
<p>Estimated daily cost for the proposed setup (Australian region):</p>
<ul>
<li>EC2 GPU Instances: ~$600-800 AUD per day</li>
<li>Supporting services: ~$100-150 AUD per day</li>
<li>RAG infrastructure: ~$50-80 AUD per day</li>
<li>Total estimated cost for a 2-day hackathon: ~$1,500-2,100 AUD</li>
</ul>
<h2 id="implementation-timeline">Implementation Timeline</h2>
<table>
<thead>
<tr>
<th>Task</th>
<th>Timeframe</th>
</tr>
</thead>
<tbody>
<tr>
<td>AWS infrastructure setup</td>
<td>2-3 days</td>
</tr>
<tr>
<td>ADFS integration</td>
<td>1-2 days</td>
</tr>
<tr>
<td>Open WebUI configuration</td>
<td>1 day</td>
</tr>
<tr>
<td>RAG components setup</td>
<td>2-3 days</td>
</tr>
<tr>
<td>Model deployment and testing</td>
<td>1-2 days</td>
</tr>
<tr>
<td>Total preparation time</td>
<td>7-11 days</td>
</tr>
</tbody>
</table>
<h2 id="business-value">Business Value</h2>
<p>This hackathon setup will allow OMC employees to:</p>
<ol>
<li><strong>Explore different model capabilities</strong> - Understand the trade-offs between model size, speed, and capabilities</li>
<li><strong>Experiment with real-world use cases</strong> - Test potential applications within OMC workflows</li>
<li><strong>Compare model performances</strong> - Evaluate which models excel at different types of tasks</li>
<li><strong>Build technical familiarity</strong> - Gain hands-on experience with LLM infrastructure</li>
<li><strong>Test RAG capabilities</strong> - Explore how retrieval augmented generation can enhance LLMs with company-specific knowledge</li>
<li><strong>Prototype potential applications</strong> - Create proof-of-concepts for using LLMs with OMC documents</li>
</ol>
<h2 id="next-steps">Next Steps</h2>
<ol>
<li>Finalize model selection and sizing requirements</li>
<li>Create detailed implementation plan</li>
<li>Set up development environment for testing</li>
<li>Configure ADFS test application</li>
<li>Develop deployment automation</li>
<li>Prepare sample document sets for RAG demonstrations</li>
</ol>
<h2 id="rag-implementation-details">RAG Implementation Details</h2>
<h3 id="document-processing-pipeline">Document Processing Pipeline</h3>
<ol>
<li>
<p><strong>Upload Interface</strong></p>
<ul>
<li>Users upload documents through Open WebUI</li>
<li>Files stored in S3 with appropriate access controls</li>
</ul>
</li>
<li>
<p><strong>Processing</strong></p>
<ul>
<li>Lambda functions triggered by S3 events</li>
<li>Documents parsed based on file type (PDF, DOCX, TXT, etc.)</li>
<li>Text extracted and chunked into appropriate segments</li>
</ul>
</li>
<li>
<p><strong>Embedding Generation</strong></p>
<ul>
<li>Text chunks processed by embedding model</li>
<li>We recommend using all-MiniLM-L6-v2 for efficiency</li>
<li>Vector embeddings generated for each text chunk</li>
</ul>
</li>
<li>
<p><strong>Storage</strong></p>
<ul>
<li>Vectors stored in PostgreSQL with pgvector extension</li>
<li>Metadata and source information preserved</li>
<li>Indexed for efficient similarity search</li>
</ul>
</li>
</ol>
<h3 id="query-flow">Query Flow</h3>
<ol>
<li>User submits a question through the interface</li>
<li>System generates embedding for the question</li>
<li>Vector store searched for relevant chunks</li>
<li>Retrieved context added to the prompt</li>
<li>LLM generates response informed by the retrieved content</li>
<li>Response displayed to user with source citations</li>
</ol>
<p>This RAG implementation enables users to get answers grounded in their own documents, making the LLM capabilities directly applicable to OMC-specific knowledge and use cases.</p>
<h2 id="network-security-and-data-privacy-controls">Network Security and Data Privacy Controls</h2>
<p>In addition to the end-to-end encryption and zero-knowledge architecture, we implement strict network isolation:</p>
<ol>
<li>
<p><strong>Complete Network Isolation</strong></p>
<ul>
<li>All LLM instances run in private subnets with no internet access</li>
<li>Special attention to DeepSeek and other models to prevent any &quot;phoning home&quot;</li>
<li>Network Activity Control Lists block all outbound traffic to public internet</li>
<li>VPC endpoints used for all AWS service communication</li>
</ul>
</li>
<li>
<p><strong>Internal-Only Accessibility</strong></p>
<ul>
<li>Models only accessible to OMC staff through the internal network</li>
<li>No external API endpoints exposed</li>
<li>Multi-layered security ensuring models cannot be reached from outside OMC</li>
</ul>
</li>
<li>
<p><strong>Communication Monitoring</strong></p>
<ul>
<li>Network flow logs monitor for any unauthorized communication attempts</li>
<li>Alerts configured for any unexpected network traffic</li>
<li>Regular security audits to verify isolation effectiveness</li>
</ul>
</li>
</ol>
<p>This network isolation strategy ensures that even models like DeepSeek, which might otherwise have privacy concerns in some deployments, are completely contained within OMC's environment with no ability to transmit data externally.</p>
<h2 id="data-security-and-privacy">Data Security and Privacy</h2>
<p>A key feature of this implementation is its robust security model that ensures all user data remains private:</p>
<ol>
<li>
<p><strong>End-to-End Encryption</strong></p>
<ul>
<li>All conversations with the LLMs are encrypted in transit</li>
<li>Encryption keys are managed per user</li>
<li>Neither DevOps nor IT teams can access the actual conversation content</li>
</ul>
</li>
<li>
<p><strong>RAG Document Security</strong></p>
<ul>
<li>Uploaded documents are processed in secure environments</li>
<li>Access controls ensure users only see their own documents and conversations</li>
</ul>
</li>
<li>
<p><strong>Zero Knowledge Architecture</strong></p>
<ul>
<li>System is designed on zero knowledge principles</li>
<li>Administrative functions do not require or permit content access</li>
<li>Monitoring and logging exclude sensitive content</li>
</ul>
</li>
<li>
<p><strong>Technical Implementation</strong></p>
<ul>
<li>Client-side security measures for document uploads</li>
<li>Separate access control mechanisms for system maintenance vs content access</li>
</ul>
</li>
</ol>
<p><strong>Note:</strong> For the hackathon implementation, we will focus on network isolation, access controls, and transport encryption. Full end-to-end encryption of stored data at rest, including client-side encryption and column-level encryption in PostgreSQL, could be implemented as a future enhancement but will not be available for the initial hackathon.</p>

</body>
</html>
